{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm to Buffer subtract, truncate, and area normalize FTIR spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5/25/18 Updated directory structure handling\n",
    "\n",
    "5/29/18 Revised buffer subtraction to use least squares regression in place of manual input of acceptable minima for iteration.  - replaced the buffer subtraction-constant iteration from a static list to a modifyable numpy arange iterator\n",
    " - modified the buffer subtraction mean value to obtain better buffer subtraction output\n",
    "\n",
    "To Do:  \n",
    "  - Investigate ways to better subtract the buffer, especially if air bubbles are present/slight changes in cell pathlength (peak area based normalization, with/without band narrowing, baseline correction, etc.)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required modules\n",
    "import sys, os, math, warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "\n",
    "from scipy.integrate import simps\n",
    "from scipy import integrate\n",
    "\n",
    "from tkinter import Tk, filedialog\n",
    "from tkinter.filedialog import askopenfilename, askopenfilenames\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import rc\n",
    "%matplotlib inline\n",
    "\n",
    "#Ignores ALL warnings. Should delete this before any serious alterations...\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "numbers = re.compile(r'(\\d+)')\n",
    "\n",
    "def numericalSort(value):\n",
    "    \"\"\"Sort function for sorting filenames numerically\"\"\"\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_file():\n",
    "    Tk().withdraw()\n",
    "\n",
    "    ftypes = [\n",
    "            ('csv or text files', '*.csv *.txt')\n",
    "            ]\n",
    "    \n",
    "    filename = str(askopenfilename(filetypes=ftypes, \n",
    "                                           title='''Select the datafile containing wavenumber in column 1, \n",
    "                                           buffer spectra in column 2, and sample spectra in remaining columns.'''))\n",
    "    folder_path = os.path.split(filename)[0]\n",
    "    filename = filename.split('/')[-1]\n",
    "    return filename, folder_path               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_files():\n",
    "    Tk().withdraw()\n",
    "\n",
    "    ftypes = [\n",
    "            ('csv or text files', '*.csv *.txt')\n",
    "            ]\n",
    "  \n",
    "    buffer_file = str(askopenfilename(filetypes=ftypes, title='Choose the buffer file.'))\n",
    "    reference_file = str(askopenfilename(filetypes=ftypes, title='Choose the reference file.'))\n",
    "    data_files = [str(i) for i in askopenfilenames(filetypes=ftypes,title='Choose the sample files.')]\n",
    "\n",
    "    folder_path = os.path.split(buffer_file)[0]\n",
    "\n",
    "    \"\"\" Sort the data files numerically by first number appearing in file name\"\"\"\n",
    "\n",
    "    data_files= sorted(data_files, key=numericalSort)\n",
    "\n",
    "    \"\"\"merge the buffer file, reference file, and sorted data file names\"\"\"  \n",
    "\n",
    "    filenames = [buffer_file] + [reference_file] + data_files       \n",
    "    filenames = [i.split('/')[-1] for i in filenames]\n",
    "\n",
    " \n",
    "    return filenames, folder_path   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_from_single_file(data_filename, folder_path):\n",
    "    \"\"\"Creates a DataFrame with protein formulations for the given input data files\"\"\"\n",
    "       \n",
    "    df = pd.read_csv(folder_path + '/' + data_filename)\n",
    "\n",
    "    df2 = df.columns.get_values()\n",
    "    filename_list = df2.tolist()\n",
    "    filenames = ['freq']\n",
    "    for f in filename_list[1:]:\n",
    "        title = f.split('.')[0]\n",
    "        filenames.append(title)\n",
    "        \n",
    "    df.columns = filenames\n",
    "\n",
    "    \"\"\"Ensures the dataframe is sorted descending wavenumber\"\"\"\n",
    "\n",
    "    df = df.sort_values(by=df.columns[0], ascending=False)\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    \"\"\"Ensures the dataframe is truncated to maximum 1000 - 3999 wavenumber range to start\"\"\"\n",
    "    df = df[(df[df.columns[0]]  < 3999) & (df[df.columns[0]]  > 999)]\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    \n",
    "    return df, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_from_multiple_files(data_filenames, folder_path):\n",
    "    \"\"\"Creates a DataFrame with protein formulations for the given input data files\"\"\"\n",
    "\n",
    "    df = pd.read_csv(folder_path + '/' + data_filenames[0], header=None)\n",
    "    df.columns = ['freq', 'buffer']\n",
    "    filenames = ['freq','buffer']\n",
    "    for f in data_filenames[1:]:\n",
    "        d = pd.read_csv(folder_path + '/' + f, usecols=[1], header=None)\n",
    "        title = f.split('.')[0]\n",
    "        d.columns = [title]\n",
    "        df = pd.concat([df, d], axis=1)\n",
    "        filenames.append(title)\n",
    "\n",
    "    \"\"\"Ensures the dataframe is sorted descending wavenumber\"\"\"\n",
    "\n",
    "    df = df.sort_values(by=['freq'], ascending=False)\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    \"\"\"Ensures the dataframe is truncated to maximum 1000 - 3999 wavenumber range to start\"\"\"\n",
    "    df = df[(df[df.columns[0]]  < 3999) & (df[df.columns[0]]  > 999)]\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    return df, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(c, df):\n",
    "    \n",
    "    df1 = df.copy()\n",
    "    \n",
    "    df1['subtr'] = df1[df1.columns[2]] - c*df1[df1.columns[1]]\n",
    "\n",
    "    df2 = df1[(df1[df1.columns[0]]  < 2500) & (df1[df1.columns[0]]  > 1690)] #orig 2500 - 1720,new 2200, 1710; peptide: 2000-2200\n",
    "    \n",
    "    df3 = df2['subtr'].rolling(min_periods=1, center=True, window=12).mean() #minimize impact of noise\n",
    "    \n",
    "    return (abs(df3.max()-df3.min()))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_constant(df):\n",
    "    \"\"\"Returns the constant to use for the buffer signal subtraction\"\"\"\n",
    "\n",
    "    min_params = optimize.minimize(fun, 1.1, args = (df))\n",
    "\n",
    "    d = 0.99*min_params.x\n",
    "    \n",
    "    print('buffer subtraction factor = ', d)\n",
    "    \n",
    "    result = df[df.columns[2]] - d*df[df.columns[1]]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buffer_subtract(df):\n",
    "    \"\"\"Updates the DataFrame to have subtracted signal data\"\"\"\n",
    "\n",
    "    result = get_constant(df)\n",
    "\n",
    "    df[df.columns[2] +'_subtracted'] = result\n",
    "    \n",
    "    df1 = df[(df[df.columns[0]] > 1729) & (df[df.columns[0]]<1731)]\n",
    "    \n",
    "    baseline_value = df1[df1.columns[3]].values[0]\n",
    "    \n",
    "    df[df.columns[3]] = result-baseline_value\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(df):\n",
    "    \"\"\"Returns a DataFrame with only the data in the frequency range [1705-1600]cm-1\"\"\"\n",
    "    df = df[(df[df.columns[0]]  < 1706) & (df[df.columns[0]] > 1599)]\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell processes the FTIR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter 1 to import all data from a single csv (with headers), or 2 for individual data and buffer files (no headers)  2\n"
     ]
    },
    {
     "ename": "TclError",
     "evalue": "no display name and no $DISPLAY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-52f6b96a0797>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mraw_data_filenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Calls select_files to read and pass back the filenames of interest in a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mrawData_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_data_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_df_from_multiple_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data_filenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#Creates the raw signal dataframe of buffer and each protein through the loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-f795c4b72730>\u001b[0m in \u001b[0;36mselect_files\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mselect_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     ftypes = [\n\u001b[1;32m      5\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0;34m'csv or text files'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*.csv *.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/saturn/lib/python3.7/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2021\u001b[0m                 \u001b[0mbaseName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2022\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2023\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2024\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2025\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable"
     ]
    }
   ],
   "source": [
    "#Block for creating basic UI and output figures/csvs.\n",
    "\n",
    "\n",
    "buff_subtracted_dataframes = [] #create empty list to store buffer subtracted data\n",
    "amideI_dataframes = []  #create empty list to store Amide I Area normalized data\n",
    "\n",
    "source_file = eval(input(\"\"\"Enter 1 to import all data from a single csv (with headers), or 2 for individual data and buffer files (no headers) \"\"\"))\n",
    "\n",
    "if source_file == 1: \n",
    "    source_file = True\n",
    "else: source_file = False\n",
    "    \n",
    "if source_file:\n",
    "    raw_data_filename, directory = select_file()\n",
    "\n",
    "    rawData_df, raw_data_filenames = create_df_from_single_file(raw_data_filename, directory)  #Creates the raw signal dataframe of buffer and each protein through the loop   \n",
    "    print(raw_data_filenames)\n",
    "    print(rawData_df.head(3))\n",
    "    \n",
    "else:\n",
    "    raw_data_filenames, directory = select_files() #Calls select_files to read and pass back the filenames of interest in a list\n",
    "    \n",
    "    rawData_df, raw_data_filenames = create_df_from_multiple_files(raw_data_filenames, directory)  #Creates the raw signal dataframe of buffer and each protein through the loop   \n",
    "    \n",
    "num_files = len(raw_data_filenames)-2 #length excludes buffer file\n",
    "initial_x_df = rawData_df.iloc[:, 0:2].copy()  #copies x-axis and buffer data for loop dataframe \n",
    "\n",
    "\n",
    "for i in range(num_files): #Loops through all selected files \n",
    "    raw_data_file = raw_data_filenames[i+2] #Loops through filename 1 - range to create buffer and protein list\n",
    "\n",
    "    raw_data_file_df1 = rawData_df[[raw_data_file]].copy()  #Creates the raw signal dataframe of buffer and each protein through the loop   \n",
    "\n",
    "    raw_data_file_df2 = pd.concat([initial_x_df, raw_data_file_df1], axis=1)\n",
    "\n",
    "    protein = raw_data_file_df2.columns[2] #Gets column name of current spectra being processed\n",
    "    print('Currently processing file: ' + protein)    \n",
    "\n",
    "    subtr_df = buffer_subtract(raw_data_file_df2).copy() #adds buffer subtracted spectra to df  \n",
    "\n",
    "    \n",
    "    full_x_df = subtr_df.iloc[:, [0]].copy()  #copies x-axis data for building buffer subtracted dataframe \n",
    "    buffsub_col = subtr_df[[protein + '_subtracted']] #Extract only the buffer subtracted column    \n",
    "    buff_subtracted_dataframes.append(buffsub_col)\n",
    "    \n",
    "    crop_df = crop(subtr_df) #truncates data to amide I region\n",
    "    crop_x_df = crop_df.iloc[:, [0]].copy()  #copies x-axis data for building buffer subtracted dataframe \n",
    "    amideI_col = crop_df[[protein + '_subtracted']]\n",
    "    amideI_dataframes.append(amideI_col)\n",
    "\n",
    "    \n",
    "all_subtracted_df = pd.concat(buff_subtracted_dataframes, axis=1)    \n",
    "all_subtracted_df = pd.concat([full_x_df, all_subtracted_df], axis=1)\n",
    "all_subtracted_df.plot(x='freq', figsize=(14,10))\n",
    "\n",
    "plt.savefig(directory +'subtr'+'.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "all_amideI_df = pd.concat(amideI_dataframes, axis=1)    \n",
    "all_amideI_df = pd.concat([crop_x_df, all_amideI_df], axis=1)\n",
    "\n",
    "all_subtracted_df.to_csv(directory + '/' + 'BufferSubtracted'+'.csv', index=False)\n",
    "all_amideI_df.to_csv(directory + '/' + 'Amide_I_Buffer_Subtracted'+'.csv', index=False)\n",
    "\n",
    "print('\\nDone!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
